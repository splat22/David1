# Predicci贸n de Monto de Pr茅stamos Digitales en Per煤

Este proyecto implementa modelos de regresi贸n lineal simple y redes neuronales para predecir el **monto de pr茅stamos digitales** otorgados a clientes peruanos. Se desarrolla con Python, TensorFlow/Keras y se documenta en un entorno reproducible como Google Colab.

---

##  Objetivo General
Predecir el monto de pr茅stamos digitales utilizando t茅cnicas de regresi贸n y redes neuronales artificiales a partir de variables disponibles en un dataset real.

---

## Objetivos Espec铆ficos
- Implementar un modelo de regresi贸n lineal simple.
- Desarrollar una red neuronal con m煤ltiples variables.
- Manipular y limpiar datos con Pandas y NumPy.
- Visualizar resultados con Matplotlib.
- Aplicar estructuras b谩sicas de programaci贸n en Python.
- Usar GitHub como sistema de control de versiones.

---

##  Descripci贸n del Dataset
El dataset fue descargado de [Kaggle](https://www.kaggle.com/) y contiene informaci贸n de pr茅stamos digitales otorgados en Per煤. Las columnas m谩s relevantes son:

- `ClienteID`: Identificador 煤nico.
- `FechaTransaccion`: Fecha de la transacci贸n.
- `Monto`: Monto del pr茅stamo.
- `TipoTransaccion`: Tipo de transacci贸n (digital, presencial, etc.).
- `Ubicacion`: Ubicaci贸n geogr谩fica.
- `FrecuenciaTransacciones`: N煤mero de transacciones realizadas (variable creada para regresi贸n).
- `UbicacionCodificada` y `TipoTransaccionCod`: Variables transformadas para la red neuronal.

---

## Tecnolog铆as y Librer铆as Usadas
- Python 3
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- TensorFlow / Keras
- Google Colab
- GitHub

---

## Modelos Aplicados

###  Regresi贸n Lineal Simple
Se utiliza una sola variable predictora: `ventaPrestDig`, para estimar el `Monto`.  
M茅tricas: MAE, MSE  
Visualizaci贸n: scatter plot con l铆nea de regresi贸n.

### Red Neuronal Artificial
- Variables de entrada: `promTrxDig3Um`, `trxDigitalUm`, `promSaldoPrest3Um`.
- Arquitectura:
  - 1 capa oculta (64 neuronas, ReLU)
  - 1 capa oculta adicional (32 neuronas, ReLU)
  - 1 capa de salida (lineal)
- M茅tricas: `mae`, `mse`
- Entrenamiento: 50 茅pocas, batch size de 10

 Visualizaciones:
- Evoluci贸n del error (`loss vs. epochs`)
- Comparaci贸n de valores reales vs. predichos

---

## L贸gica de Programaci贸n
El c贸digo incluye:
- Un bucle `for` para calcular errores de predicci贸n.
- Condicional `if` para filtrar predicciones cercanas.
- Uso de `listas` y `diccionarios` para almacenar resultados.

---

## Ejemplos de Visualizaciones
Agrega aqu铆 capturas de pantalla desde el Colab:

- ![Gr谩fica Regresi贸n Lineal](ruta/lineal.png)
- ![Gr谩fica Red Neuronal](ruta/neural.png)
- ![Error vs pocas](ruta/loss_plot.png)

---

## C贸mo Ejecutar este Proyecto
1. Abre el archivo `.ipynb` en [Google Colab](https://colab.research.google.com/).
2. Sube el dataset `prestamos_peru.csv` desde tu m谩quina.
3. Ejecuta cada celda secuencialmente.
4. Observa las predicciones, gr谩ficas y m茅tricas generadas.

---

## Conclusiones
- La regresi贸n lineal es 煤til pero limitada cuando hay m煤ltiples variables.
- Las redes neuronales capturan mejor relaciones no lineales complejas.
- Python con TensorFlow/Keras permite construir modelos potentes con poco c贸digo.
- Documentar en GitHub facilita compartir y colaborar en proyectos de ciencia de datos.

---

## Autor
**victor david huayta huaripoma**  
[GitHub](https://github.com/splat22/David1) | [Google Colad](https://colab.research.google.com/drive/1hra-xTwLFMWksw32DSZND2PtamB4kj20?usp=sharing)
